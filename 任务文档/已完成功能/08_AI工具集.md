# AI 工具集与沙箱执行 (AI Tools & Sandbox Execution)

## 1. 概览
为了赋予 AI 更强的能力，我们实现了一套工具集 (Tools)，允许 AI 在安全的沙箱环境中执行 Bash 命令、读写文件和列出目录。这使得 AI 不仅能生成代码，还能实际操作文件系统和运行脚本。

## 2. 核心组件

### 2.1 SandboxManager (`src/lib/sandbox/manager.ts`)
- **功能**: 管理 Docker 容器生命周期，执行命令。
- **改进**: 
    - 修复了 `execCommand` 中的流处理逻辑，正确解析 Docker exec 的 stdout/stderr。
    - 支持为每个项目/用户创建独立的隔离工作区 (`workspaces/<projectId>`)。

### 2.2 AI Tools 定义 (`src/app/api/chat/tools.ts`)
使用 Vercel AI SDK 的 `tool` 函数定义了以下工具：
- `executeBash`: 执行 Shell 命令 (如 `ls`, `cat`, `python3 script.py`)。
- `readFile`: 读取沙箱中的文件内容。
- `writeFile`: 向沙箱写入文件 (使用 Base64 编码避免特殊字符问题)。
- `listFiles`: 列出当前目录结构。

### 2.3 API 集成 (`src/app/api/chat/route.ts`)
- **集成**: 在 `generateText` 调用中注入 `tools`。
- **多步执行**: 启用 `maxSteps: 5`，允许 AI 进行推理->执行->观察->再执行的循环。
- **调试**: 添加了文件日志 (`debug_chat.log`) 以追踪 AI 的思考过程和工具调用情况。
- **模型配置**: 增加了对 Google Gemini 和 Llama 等模型的支持 (需模型本身支持 Function Calling)。

## 3. 使用方法

### 3.1 环境变量
在 `.env.local` 中配置：
```bash
GEMINI_MODEL_ID=meta-llama/llama-3.3-70b-instruct:free # 或其他支持工具的模型
```
> **注意**: 目前 OpenRouter 上的 DeepSeek R1 免费版不支持工具调用，建议升级模型或使用支持 func calling 的模型。

### 3.2 调用测试
根目录下提供了 `test_tools_local.py` 脚本：
```bash
python3 test_tools_local.py
```
此脚本会向本地 API 发送请求，指示 AI 创建一个文件并验证。

## 4. 安全性
- **Docker 隔离**: 所有命令在 `atoms-sandbox` 容器内运行，虽挂载了主机目录 `workspaces/`，但仅限于该目录。
- **命令审计**: 所有执行的命令都会在日志中记录。

## 5. 已知问题
- **模型兼容性**: 严重依赖于大模型的 Function Calling 能力。免费模型 (如 DeepSeek R1 free) 往往不支持，需切换到更高级模型。
